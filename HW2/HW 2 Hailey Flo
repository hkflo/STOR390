---
title: "HW 2 Hailey Flo"
author: "Hailey Flo"
date: "02/14/2024"
output: 
  html_document:
    number_sections: true
---

This homework is meant to illustrate the methods of classification algorithms as well as their potential pitfalls.  In class, we demonstrated K-Nearest-Neighbors using the `iris` dataset.  Today I will give you a different subset of this same data, and you will train a KNN classifier.  

```{r, echo = FALSE}
set.seed(123)
library(class)

df <- data(iris) 

normal <-function(x) {
  (x -min(x))/(max(x)-min(x))   
}

iris_norm <- as.data.frame(lapply(iris[,c(1,2,3,4)], normal))

subset <- c(1:45, 58, 60:70, 82, 94, 110:150)
iris_train <- iris_norm[subset,] 
iris_test <- iris_norm[-subset,] 

iris_target_category <- iris[subset,5]
iris_test_category <- iris[-subset,5]


```

#
Above, I have given you a training-testing partition.  Train the KNN with $K = 5$ on the training data and use this to classify the 50 test observations.  Once you have classified the test observations, create a contingency table -- like we did in class -- to evaluate which observations your algorithm is misclassifying.   

```{r}
set.seed(123)

pr <- knn(iris_train, iris_test, cl=iris_target_category, k=5)
tab <- table(pr, iris_test_category)
tab


accuracy <- function(x){
  sum(diag(x))/(sum(rowSums(x)))*100
}

accuracy(tab)

```

#

Discuss your results.  If you have done this correctly, you should have a classification error rate that is roughly 20% higher than what we observed in class.  Why is this the case? In particular run a summary of the `iris_test_category` as well as `iris_target_category` and discuss how this plays a role in your answer.  

```{r}
summary(iris_test_category)
summary(iris_target_category)
```
This testing set has a much higher error rate than the one we found in class because it had issues classifying the virginica data. The contingency table shows that 11 out of our 50 data points in the test set were falsely classified, all of which were virginica. Based off the summaries of the testing and target categories we can see why. The testing set used much higher ratios of data from the other two categories, setosa and versicolor, than it did virginica. The target category contains 40 setosa points and 45 virginica points, however the test set includes double the amount of setosa points as virginica. This unbalanced amount of data for virginica flowers explains why so many of these points were misclassified in the testing set.


#

Build a github repository to store your homework assignments.  Share the link in this file.  

https://github.com/hkflo/STOR390
